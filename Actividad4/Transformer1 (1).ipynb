{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "s6UJgyRHsJO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV9FmWuzdEyc",
        "outputId": "af87b456-f1ee-4f50-dabf-6f2a094994ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creacion csv y limpieza de datos"
      ],
      "metadata": {
        "id": "VSl4_u6Ne94A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg.csv'\n",
        "ruta_csv_acl = '/content/drive/MyDrive/acl_datos_completos.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv)\n",
        "df_acl = pd.read_csv(ruta_csv_acl)\n",
        "\n",
        "# Copiar el contenido de la columna \"Accepted\" en las filas correspondientes de df\n",
        "for index, row in df.iterrows():\n",
        "    archivo = row['archivo']\n",
        "    accepted_value = df_acl.loc[df_acl['Archivo'] == archivo, 'Accepted'].values\n",
        "    if len(accepted_value) > 0:\n",
        "        df.at[index, 'label'] = accepted_value[0]\n",
        "\n",
        "# Ruta para guardar el archivo modificado\n",
        "ruta_guardado = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg.csv'\n",
        "\n",
        "# Guardar el DataFrame modificado en la nueva ruta\n",
        "df.to_csv(ruta_guardado, index=False)\n",
        "\n",
        "print(\"DataFrame modificado guardado en:\", ruta_guardado)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXl3_0ykpo5R",
        "outputId": "b763b5f5-00db-4878-9c7a-273371e3d3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame modificado guardado en: /content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/iclr_img/data.csv'\n",
        "ruta_csv_acl = '/content/drive/MyDrive/iclr_datos_completos.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv, encoding='latin1')  #'latin1', 'iso-8859-1' o 'cp1252'\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "df_acl = pd.read_csv(ruta_csv_acl)\n",
        "#print (df_acl)\n",
        "\n",
        "#if 'Etiqueta' not in df.columns:\n",
        "#    # Si no está presente, agregar la columna al DataFrame con valores NaN\n",
        "#    df['Etiqueta '] = None\n",
        "\n",
        "# Copiar el contenido de la columna \"Accepted\" en las filas correspondientes de df\n",
        "for index, row in df.iterrows():\n",
        "    archivo = row['archivo']  # Accede a la columna sin espacio en el nombre\n",
        "    accepted_value = df_acl.loc[df_acl['Archivo'] == archivo, 'Accepted'].values\n",
        "    if len(accepted_value) > 0:\n",
        "        df.at[index, 'label'] = accepted_value[0]\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Ruta para guardar el archivo modificado\n",
        "ruta_guardado = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_Papers_labeled2.csv'\n",
        "\n",
        "# Guardar el DataFrame modificado en la nueva ruta\n",
        "df.to_csv(ruta_guardado, index=False)\n",
        "\n",
        "print(\"DataFrame modificado guardado en:\", ruta_guardado)"
      ],
      "metadata": {
        "id": "4qcGFnjj6hLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/iclr_img/data3.xlsx'\n",
        "ruta_csv_acl = '/content/drive/MyDrive/iclr_datos_completos.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_excel(ruta_csv)  #'latin1', 'iso-8859-1' o 'cp1252'\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "df_acl = pd.read_csv(ruta_csv_acl)\n",
        "#print (df_acl)\n",
        "\n",
        "#if 'Etiqueta' not in df.columns:\n",
        "#    # Si no está presente, agregar la columna al DataFrame con valores NaN\n",
        "#    df['Etiqueta '] = None\n",
        "\n",
        "# Copiar el contenido de la columna \"Accepted\" en las filas correspondientes de df\n",
        "for index, row in df.iterrows():\n",
        "    archivo = row['archivo']  # Accede a la columna sin espacio en el nombre\n",
        "    accepted_value = df_acl.loc[df_acl['Archivo'] == archivo, 'Accepted'].values\n",
        "    if len(accepted_value) > 0:\n",
        "        df.at[index, 'label'] = accepted_value[0]\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Ruta para guardar el archivo modificado\n",
        "ruta_guardado = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_Papers_labeled2.csv'\n",
        "\n",
        "# Guardar el DataFrame modificado en la nueva ruta\n",
        "df.to_csv(ruta_guardado, index=False)\n",
        "\n",
        "print(\"DataFrame modificado guardado en:\", ruta_guardado)"
      ],
      "metadata": {
        "id": "35Un1qeRwt58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg.csv'\n",
        "ruta_csv_acl = '/content/drive/MyDrive/acl_datos_completos.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv)\n",
        "df_acl = pd.read_csv(ruta_csv_acl)\n",
        "\n",
        "# Copiar el contenido de la columna \"Accepted\" en las filas correspondientes de df\n",
        "for index, row in df.iterrows():\n",
        "    archivo = row['archivo']\n",
        "    accepted_value = df_acl.loc[df_acl['Archivo'] == archivo, 'Accepted'].values\n",
        "    if len(accepted_value) > 0:\n",
        "        df.at[index, 'label'] = accepted_value[0]\n",
        "\n",
        "# Eliminar filas con datos vacíos en las columnas especificadas ('archivo' y 'label')\n",
        "df_cleaned = df.dropna(subset=['archivo', 'texto_figura'])\n",
        "\n",
        "# Ruta para guardar el archivo modificado\n",
        "ruta_guardado = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg_cleaned.csv'\n",
        "\n",
        "# Guardar el DataFrame limpio en la nueva ruta\n",
        "df_cleaned.to_csv(ruta_guardado, index=False)\n",
        "\n",
        "print(\"DataFrame modificado y limpio guardado en:\", ruta_guardado)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aKnECeEe0dK",
        "outputId": "5ca9d197-8ca0-4c72-a8c4-096d76b2bef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame modificado y limpio guardado en: /content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/iclr_img/data.csv'\n",
        "ruta_csv_acl = '/content/drive/MyDrive/iclr_datos_completos.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv, encoding='latin1')  #'latin1', 'iso-8859-1' o 'cp1252'\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "df_acl = pd.read_csv(ruta_csv_acl)\n",
        "#print (df_acl)\n",
        "\n",
        "\n",
        "# Copiar el contenido de la columna \"Accepted\" en las filas correspondientes de df\n",
        "for index, row in df.iterrows():\n",
        "    archivo = row['archivo']  # Accede a la columna sin espacio en el nombre\n",
        "    accepted_value = df_acl.loc[df_acl['Archivo'] == archivo, 'Accepted'].values\n",
        "    if len(accepted_value) > 0:\n",
        "        df.at[index, 'label'] = accepted_value[0]\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Ruta para guardar el archivo modificado\n",
        "ruta_guardado = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_Papers_labeled2.csv'\n",
        "\n",
        "# Guardar el DataFrame modificado en la nueva ruta\n",
        "df.to_csv(ruta_guardado, index=False)\n",
        "\n",
        "print(\"DataFrame modificado guardado en:\", ruta_guardado)"
      ],
      "metadata": {
        "id": "qXUqeLHsTCqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg_iclr_similaridad_stopwords.csv'\n",
        "ruta_csv_acl = '/content/drive/MyDrive/iclr_datos_completos.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv, encoding='latin1')  #'latin1', 'iso-8859-1' o 'cp1252'\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "df_acl = pd.read_csv(ruta_csv_acl)\n",
        "#print (df_acl)\n",
        "\n",
        "\n",
        "# Copiar el contenido de la columna \"Accepted\" en las filas correspondientes de df\n",
        "for index, row in df.iterrows():\n",
        "    archivo = row['archivo']  # Accede a la columna sin espacio en el nombre\n",
        "    accepted_value = df_acl.loc[df_acl['Archivo'] == archivo, 'Accepted'].values\n",
        "    if len(accepted_value) > 0:\n",
        "        df.at[index, 'label'] = accepted_value[0]\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Ruta para guardar el archivo modificado\n",
        "ruta_guardado = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_iclr_stop_labeled_2.csv'\n",
        "\n",
        "# Guardar el DataFrame modificado en la nueva ruta\n",
        "df.to_csv(ruta_guardado, index=False)\n",
        "\n",
        "print(\"DataFrame modificado guardado en:\", ruta_guardado)"
      ],
      "metadata": {
        "id": "nKe3_RTT-ctr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# similaridad pruebas"
      ],
      "metadata": {
        "id": "2bku68kke2YV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv)\n",
        "print(df.head())\n",
        "\n",
        "# Seleccionar modelo preentrenado\n",
        "#model = SentenceTransformer('clip-ViT-B-32')\n",
        "model = SentenceTransformer('clip-ViT-L-14')\n",
        "\n",
        "# Lista para almacenar las puntuaciones de similitud\n",
        "similarity_scores = []\n",
        "\n",
        "# Iterar sobre cada fila del df\n",
        "for index, row in df.iterrows():\n",
        "    # Obtener los valores de las columnas para la fila actual\n",
        "    archivo = row['archivo']\n",
        "    figura = row['figura']\n",
        "    texto_figura = row['texto_figura']\n",
        "    label = row['label']\n",
        "    ruta = row['ruta']\n",
        "    ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/Extraer IMG/', ruta,figura +\".png\")\n",
        "    print(ruta_completa)\n",
        "\n",
        "\n",
        "    # Encode an image:\n",
        "    img_emb = model.encode(Image.open(ruta_completa))\n",
        "\n",
        "    # Encode text description\n",
        "    text_emb = model.encode([texto_figura])\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    cos_scores = util.cos_sim(img_emb, text_emb)\n",
        "\n",
        "    # Agregar el resultado de la similitud al DataFrame\n",
        "    similarity_scores.append(cos_scores[0])\n",
        "\n",
        "    # Resultados\n",
        "    print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {cos_scores}\")\n",
        "\n",
        "# Agregar una nueva columna con las similaridades de cada figura\n",
        "df['similaridad'] = similarity_scores\n",
        "\n",
        "# Guardar el nuevo DataFrame con la columna de similitud como un nuevo archivo CSV\n",
        "ruta_nuevo_csv = '/content/drive/MyDrive/ruta/al/dataimg_con_similaridad.csv'\n",
        "df.to_csv(ruta_nuevo_csv, index=False)\n",
        "print(df.head())\n",
        "\n",
        "# Imprimir mensaje de confirmación\n",
        "print(f\"Archivo CSV con la columna 'similaridad' guardado en: {ruta_nuevo_csv}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oK9bB7WMdx5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "TqK99YqJrRmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Cargar el tokenizador y el modelo desde Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nombre-del-modelo-o-la-ruta-al-modelo-en-disco\")\n",
        "model = AutoModel.from_pretrained(\"nombre-del-modelo-o-la-ruta-al-modelo-en-disco\")\n",
        "\n",
        "# Oraciones que deseas codificar\n",
        "sentences = ['Esta es la primera oración.', 'Esta es la segunda oración.']\n",
        "\n",
        "# Tokenizar las oraciones\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Calcular las incrustaciones (embeddings)\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "\n",
        "# Realizar pooling, por ejemplo, mean pooling\n",
        "token_embeddings = model_output.last_hidden_state\n",
        "attention_mask = encoded_input['attention_mask'].unsqueeze(-1).expand(token_embeddings.size())\n",
        "sum_embeddings = torch.sum(token_embeddings * attention_mask, dim=1)\n",
        "sum_mask = torch.clamp(attention_mask.sum(1), min=1e-9)\n",
        "sentence_embeddings = sum_embeddings / sum_mask\n",
        "\n",
        "# Las embeddings de las oraciones estarán en sentence_embeddings\n"
      ],
      "metadata": {
        "id": "9Wi8xSmpKfjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg_cleaned2.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv)\n",
        "print(df.head())\n",
        "\n",
        "# Seleccionar modelo preentrenado\n",
        "model = SentenceTransformer('clip-ViT-B-32', device='cuda')\n",
        "\n",
        "# Lista para almacenar las puntuaciones de similitud\n",
        "similarity_scores = []\n",
        "\n",
        "# Iterar sobre cada fila del df\n",
        "for index, row in df.iterrows():\n",
        "    # Obtener los valores de las columnas para la fila actual\n",
        "    archivo = row['archivo']\n",
        "    figura = row['figura']\n",
        "    texto_figura = row['texto_figura']\n",
        "    label = row['label']\n",
        "    ruta = row['ruta']\n",
        "\n",
        "    # Verificar si ruta y figura son valores válidos\n",
        "    if ruta and figura:\n",
        "        ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/Extraer IMG/', str(ruta), figura + \".png\")\n",
        "\n",
        "        # Encode an image\n",
        "        img_emb = model.encode(Image.open(ruta_completa), convert_to_tensor=True)\n",
        "\n",
        "        # Encode text description using mean pooling\n",
        "        text_embeddings = model.encode([texto_figura], convert_to_tensor=True)\n",
        "        attention_mask = torch.ones_like(text_embeddings)  # Attention mask with ones for all tokens\n",
        "        text_emb = torch.sum(text_embeddings * attention_mask, dim=1) / torch.sum(attention_mask, dim=1)\n",
        "\n",
        "        # Ensure compatible dimensions for multiplication\n",
        "        text_emb = text_emb.squeeze(0)\n",
        "        # Asegurarte de que text_emb tenga las mismas dimensiones que img_emb\n",
        "        text_emb_expanded = text_emb.expand_as(img_emb)\n",
        "\n",
        "        # Calcular las puntuaciones de similitud del coseno\n",
        "        cos_scores = util.pytorch_cos_sim(img_emb, text_emb_expanded).item()\n",
        "\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "        similarity_scores.append(cos_scores)\n",
        "\n",
        "        # Resultados\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {cos_scores}\")\n",
        "\n",
        "    else:\n",
        "        # Si ruta o figura son nulos, continuar con la próxima iteración\n",
        "        continue\n",
        "\n",
        "# Agregar una nueva columna con las similaridades de cada figura\n",
        "df['similaridad'] = similarity_scores\n",
        "\n",
        "# Guardar el nuevo DataFrame con la columna de similitud como un nuevo archivo CSV\n",
        "ruta_nuevo_csv = '/content/drive/MyDrive/ruta/al/dataimg_con_similaridad_pruebita.csv'\n",
        "df.to_csv(ruta_nuevo_csv, index=False)\n",
        "print(df.head())\n",
        "\n",
        "# Imprimir mensaje de confirmación\n",
        "print(f\"Archivo CSV con la columna 'similaridad' guardado en: {ruta_nuevo_csv}\")\n"
      ],
      "metadata": {
        "id": "pautnWGSQt2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Similaridad FINAL\n"
      ],
      "metadata": {
        "id": "8m6vdEizoRoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "\n",
        "# ruta archivo\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg.csv'\n",
        "\n",
        "# leer el archivo csv y convertirlo en DataFrame\n",
        "df = pd.read_csv(ruta_csv)\n",
        "print(df.head())\n",
        "\n",
        "# Función para contar las palabras en un texto\n",
        "def contar_palabras(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "        palabras = texto.split()\n",
        "        return len(palabras)\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor reuerido\n",
        "        return 0\n",
        "\n",
        "# Función para limpiar texto\n",
        "def limpiar_texto(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "\n",
        "        texto_limpio = re.sub(r'[^\\x00-\\x7F]+', ' ', texto)  # Eliminar caracteres no en inglés\n",
        "        texto_limpio = re.sub(r'[^\\w\\s]', '', texto_limpio)  # Eliminar signos de puntuación\n",
        "        texto_limpio = re.sub(r'\\s+', ' ', texto_limpio).strip()  # Reemplazar espacios dobles por uno solo\n",
        "        return texto_limpio\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor asignado\n",
        "        return ''\n",
        "\n",
        "\n",
        "def similaridad(texto,ruta):\n",
        "  text_tokens = model.tokenize([texto])\n",
        "  #print(text_tokens)\n",
        "  num_tokens = len(text_tokens['input_ids'][0])\n",
        "  print(num_tokens)\n",
        "\n",
        "  if num_tokens <= 77:\n",
        "    # Encode an image:\n",
        "    print(ruta)\n",
        "    img_emb = model.encode(Image.open(ruta), convert_to_tensor=True)\n",
        "\n",
        "    text_emb = model.encode([texto], convert_to_tensor=True)\n",
        "    # Ensure compatible dimensions for multiplication\n",
        "    text_emb = text_emb.squeeze(0)\n",
        "    # escalar text_emb para que tenga las mismas dimensiones que img_emb\n",
        "    text_emb_expanded = text_emb.expand_as(img_emb)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    cos_scores = util.cos_sim(img_emb, text_emb_expanded)\n",
        "    return cos_scores\n",
        "  else:\n",
        "    # Dividir el texto exactamente a la mitad\n",
        "    longitud_texto = len(texto)\n",
        "    mitad = longitud_texto // 2\n",
        "    fragmento1 = texto[:mitad]\n",
        "    fragmento2 = texto[mitad:]\n",
        "\n",
        "    # Llamar recursivamente la función similaridad para ambos fragmentos\n",
        "    cos_scores1 = similaridad(fragmento1, ruta)\n",
        "    cos_scores2 = similaridad(fragmento2, ruta)\n",
        "\n",
        "    # Calcular el promedio de las similitudes de ambos fragmentos\n",
        "    promedio_similitudes = (cos_scores1 + cos_scores2) / 2\n",
        "    return promedio_similitudes\n",
        "\n",
        "\n",
        "# Agregar nueva columna llamada \"tamano\"\n",
        "df['tamano'] = df['texto_figura'].apply(contar_palabras)\n",
        "\n",
        "# Seleccionar modelo preentrenado\n",
        "model = SentenceTransformer('clip-ViT-B-32')\n",
        "#model = SentenceTransformer('clip-ViT-B-32', device='cuda')\n",
        "\n",
        "# Lista para almacenar las puntuaciones de similitud\n",
        "similarity_scores = []\n",
        "\n",
        "# Iterar sobre cada fila del df\n",
        "for index, row in df.iterrows():\n",
        "    # Obtener los valores de las columnas para la fila actual\n",
        "    archivo = row['archivo']\n",
        "    figura = row['figura']\n",
        "    texto_figura = row['texto_figura']\n",
        "    label = row['label']\n",
        "    ruta = row['ruta']\n",
        "\n",
        "    # Limitar la longitud del texto\n",
        "    texto_figura_limpio = limpiar_texto(texto_figura)\n",
        "    # Encode text description\n",
        "    print(texto_figura_limpio)\n",
        "\n",
        "    # Verificar si ruta y figura son valores válidos\n",
        "    if ruta and isinstance(figura, str):\n",
        "        #ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/Extraer IMG/', ruta, figura + \".png\")\n",
        "        ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/Extraer IMG/', str(ruta), figura + \".png\")\n",
        "\n",
        "        #obtenet similaridad\n",
        "        cos_scores = similaridad(texto_figura_limpio,ruta_completa)\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "\n",
        "        # Obtener similitud como valor numérico\n",
        "        cos_score_numeric = cos_scores.item()\n",
        "        print(cos_score_numeric)\n",
        "\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "        similarity_scores.append(cos_score_numeric)\n",
        "\n",
        "        # Resultados\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {cos_scores}\")\n",
        "\n",
        "    else:\n",
        "        # Si ruta o figura no son válidos asignar la frase y continuar\n",
        "        similaridad_frase = \"No contiene IMÁGENES\"\n",
        "        similarity_scores.append(similaridad_frase)\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {similaridad_frase}\")\n",
        "        continue\n",
        "\n",
        "# Agregar una nueva columna con las similaridades de cada figura\n",
        "similaridad_scores_cpu = [score.cpu().numpy()[0] if isinstance(score, torch.Tensor) else score for score in similarity_scores]\n",
        "df['similaridad'] = similaridad_scores_cpu\n",
        "\n",
        "# Guardar el nuevo DataFrame con la columna 'tamano' y 'similaridad' como un nuevo archivo CSV\n",
        "ruta_nuevo_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg_con_similaridad.csv'\n",
        "df.to_csv(ruta_nuevo_csv, index=False)\n",
        "print(df.head())\n",
        "\n",
        "# Imprimir mensaje de confirmación\n",
        "print(f\"Archivo CSV con las columnas 'tamano' y 'similaridad' guardado en: {ruta_nuevo_csv}\")\n"
      ],
      "metadata": {
        "id": "NyhVOvBZ2W23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "\n",
        "# ruta archivo\n",
        "ruta_csv1 = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_Papers_labeled - CSV_Papers_labeled (2).csv'\n",
        "ruta_csv2 = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_Papers_labeled2.csv'\n",
        "# leer el archivo csv y convertirlo en DataFrame\n",
        "df1 = pd.read_csv(ruta_csv1)\n",
        "df2 = pd.read_csv(ruta_csv2)\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "print(df.head())\n",
        "\n",
        "# Función para contar las palabras en un texto\n",
        "def contar_palabras(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "        palabras = texto.split()\n",
        "        return len(palabras)\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor reuerido\n",
        "        return 0\n",
        "\n",
        "# Función para limpiar texto\n",
        "def limpiar_texto(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "\n",
        "        texto_limpio = re.sub(r'[^\\x00-\\x7F]+', ' ', texto)  # Eliminar caracteres no en inglés\n",
        "        texto_limpio = re.sub(r'[^\\w\\s]', '', texto_limpio)  # Eliminar signos de puntuación\n",
        "        texto_limpio = re.sub(r'\\s+', ' ', texto_limpio).strip()  # Reemplazar espacios dobles por uno solo\n",
        "        return texto_limpio\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor asignado\n",
        "        return ''\n",
        "\n",
        "\n",
        "def similaridad(texto,ruta):\n",
        "  text_tokens = model.tokenize([texto])\n",
        "  #print(text_tokens)\n",
        "  num_tokens = len(text_tokens['input_ids'][0])\n",
        "  print(num_tokens)\n",
        "\n",
        "  if num_tokens <= 77:\n",
        "    # Encode an image:\n",
        "    print(ruta)\n",
        "    img_emb = model.encode(Image.open(ruta), convert_to_tensor=True)\n",
        "\n",
        "    text_emb = model.encode([texto], convert_to_tensor=True)\n",
        "    # Ensure compatible dimensions for multiplication\n",
        "    text_emb = text_emb.squeeze(0)\n",
        "    # escalar text_emb para que tenga las mismas dimensiones que img_emb\n",
        "    text_emb_expanded = text_emb.expand_as(img_emb)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    cos_scores = util.cos_sim(img_emb, text_emb_expanded)\n",
        "    return cos_scores\n",
        "  else:\n",
        "    # Dividir el texto exactamente a la mitad\n",
        "    longitud_texto = len(texto)\n",
        "    mitad = longitud_texto // 2\n",
        "    fragmento1 = texto[:mitad]\n",
        "    fragmento2 = texto[mitad:]\n",
        "\n",
        "    # Llamar recursivamente la función similaridad para ambos fragmentos\n",
        "    cos_scores1 = similaridad(fragmento1, ruta)\n",
        "    cos_scores2 = similaridad(fragmento2, ruta)\n",
        "\n",
        "    # Calcular el promedio de las similitudes de ambos fragmentos\n",
        "    promedio_similitudes = (cos_scores1 + cos_scores2) / 2\n",
        "    return promedio_similitudes\n",
        "\n",
        "# Agregar nueva columna llamada \"tamano\"\n",
        "df['tamano'] = df['texto_figura'].apply(contar_palabras)\n",
        "\n",
        "# Seleccionar modelo preentrenado\n",
        "model = SentenceTransformer('clip-ViT-B-32')\n",
        "#model = SentenceTransformer('clip-ViT-B-32', device='cuda')\n",
        "\n",
        "# Lista para almacenar las puntuaciones de similitud\n",
        "similarity_scores = []\n",
        "\n",
        "# Iterar sobre cada fila del df\n",
        "for index, row in df.iterrows():\n",
        "    # Obtener los valores de las columnas para la fila actual\n",
        "    archivo = row['archivo']\n",
        "    figura = row['figura']\n",
        "    texto_figura = row['texto_figura']\n",
        "    label = row['label']\n",
        "    ruta = row['ruta']\n",
        "\n",
        "    # Limitar la longitud del texto\n",
        "    texto_figura_limpio = limpiar_texto(texto_figura)\n",
        "    # Encode text description\n",
        "    print(texto_figura_limpio)\n",
        "\n",
        "    # Verificar si ruta y figura son valores válidos\n",
        "    if ruta and isinstance(figura, str):\n",
        "        ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/iclr_img/', str(ruta), figura + \".png\")\n",
        "\n",
        "        #obtenet similaridad\n",
        "        cos_scores = similaridad(texto_figura_limpio,ruta_completa)\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "\n",
        "        # Obtener similitud como valor numérico\n",
        "        cos_score_numeric = cos_scores.item()\n",
        "        print(cos_score_numeric)\n",
        "\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "        similarity_scores.append(cos_score_numeric)\n",
        "\n",
        "        # Resultados\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {cos_scores}\")\n",
        "\n",
        "    else:\n",
        "        # Si ruta o figura no son válidos asignar la frase y continuar\n",
        "        similaridad_frase = \"No contiene IMÁGENES\"\n",
        "        similarity_scores.append(similaridad_frase)\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {similaridad_frase}\")\n",
        "        continue\n",
        "\n",
        "# Agregar una nueva columna con las similaridades de cada figura\n",
        "similaridad_scores_cpu = [score.cpu().numpy()[0] if isinstance(score, torch.Tensor) else score for score in similarity_scores]\n",
        "df['similaridad'] = similaridad_scores_cpu\n",
        "\n",
        "# Guardar el nuevo DataFrame con la columna 'tamano' y 'similaridad' como un nuevo archivo CSV\n",
        "ruta_nuevo_csv = '/content/drive/MyDrive/pruebasNadia/iclr_img/dataimg_con_similaridad_stop.csv'\n",
        "df.to_csv(ruta_nuevo_csv, index=False)\n",
        "print(df.head())\n",
        "\n",
        "# Imprimir mensaje de confirmación\n",
        "print(f\"Archivo CSV con las columnas 'tamano' y 'similaridad' guardado en: {ruta_nuevo_csv}\")\n"
      ],
      "metadata": {
        "id": "ANyiKZTPZJX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FINAL CON STOPWORDS"
      ],
      "metadata": {
        "id": "vZeSFsnrqK2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg.csv'\n",
        "\n",
        "# Leer el archivo CSV y convertirlo en un DataFrame\n",
        "df = pd.read_csv(ruta_csv)\n",
        "print(df.head())\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Función para contar las palabras en un texto\n",
        "def contar_palabras(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "        palabras = texto.split()\n",
        "        return len(palabras)\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor 0\n",
        "        return 0\n",
        "\n",
        "# Función para limpiar texto\n",
        "def limpiar_texto(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "\n",
        "        texto_limpio = re.sub(r'[^\\x00-\\x7F]+', ' ', texto)  # Eliminar caracteres no en inglés\n",
        "        texto_limpio = re.sub(r'[^\\w\\s]', '', texto_limpio)  # Eliminar signos de puntuación\n",
        "        texto_limpio = re.sub(r'\\s+', ' ', texto_limpio).strip()  # Reemplazar espacios dobles por uno solo\n",
        "\n",
        "        # Filtrar stopwords en inglés\n",
        "        words = texto_limpio.split()\n",
        "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "        texto_filtrado = ' '.join(filtered_words)\n",
        "\n",
        "        return texto_filtrado\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor asignado\n",
        "        return ''\n",
        "\n",
        "\n",
        "def similaridad(texto,ruta):\n",
        "  text_tokens = model.tokenize([texto])\n",
        "  #print(text_tokens)\n",
        "  num_tokens = len(text_tokens['input_ids'][0])\n",
        "  print(num_tokens)\n",
        "\n",
        "  if num_tokens <= 77:\n",
        "    # Encode an image:\n",
        "    print(ruta)\n",
        "    img_emb = model.encode(Image.open(ruta), convert_to_tensor=True)\n",
        "\n",
        "    text_emb = model.encode([texto], convert_to_tensor=True)\n",
        "    # Ensure compatible dimensions for multiplication\n",
        "    text_emb = text_emb.squeeze(0)\n",
        "    # Asegurarte de que text_emb tenga las mismas dimensiones que img_emb\n",
        "    text_emb_expanded = text_emb.expand_as(img_emb)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    cos_scores = util.cos_sim(img_emb, text_emb_expanded)\n",
        "    return cos_scores\n",
        "  else:\n",
        "    # Dividir el texto exactamente a la mitad\n",
        "    longitud_texto = len(texto)\n",
        "    mitad = longitud_texto // 2\n",
        "    fragmento1 = texto[:mitad]\n",
        "    fragmento2 = texto[mitad:]\n",
        "\n",
        "    # Llamar recursivamente la función similaridad para ambos fragmentos\n",
        "    cos_scores1 = similaridad(fragmento1, ruta)\n",
        "    cos_scores2 = similaridad(fragmento2, ruta)\n",
        "\n",
        "    # Calcular el promedio de las similitudes de ambos fragmentos\n",
        "    promedio_similitudes = (cos_scores1 + cos_scores2) / 2\n",
        "    return promedio_similitudes\n",
        "\n",
        "# Agregar nueva columna llamada \"tamano\"\n",
        "df['tamano'] = df['texto_figura'].apply(contar_palabras)\n",
        "\n",
        "# Seleccionar modelo preentrenado\n",
        "model = SentenceTransformer('clip-ViT-B-32')\n",
        "#model = SentenceTransformer('clip-ViT-B-32', device='cuda')\n",
        "\n",
        "# Lista para almacenar las puntuaciones de similitud\n",
        "similarity_scores = []\n",
        "\n",
        "# Iterar sobre cada fila del df\n",
        "for index, row in df.iterrows():\n",
        "    # Obtener los valores de las columnas para la fila actual\n",
        "    archivo = row['archivo']\n",
        "    figura = row['figura']\n",
        "    texto_figura = row['texto_figura']\n",
        "    label = row['label']\n",
        "    ruta = row['ruta']\n",
        "\n",
        "    # Limitar la longitud del texto\n",
        "    texto_figura_limpio = limpiar_texto(texto_figura)\n",
        "    # Encode text description\n",
        "    print(texto_figura_limpio)\n",
        "\n",
        "    # Verificar si ruta y figura son valores válidos\n",
        "    if ruta and isinstance(figura, str):\n",
        "        #ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/Extraer IMG/', ruta, figura + \".png\")\n",
        "        ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/Extraer IMG/', str(ruta), figura + \".png\")\n",
        "\n",
        "        vectorizer = CountVectorizer()\n",
        "        texto_vectorizado = vectorizer.fit_transform([texto_figura_limpio])\n",
        "        texto_vectorizado_str = ' '.join(vectorizer.inverse_transform(texto_vectorizado)[0].astype(str))\n",
        "\n",
        "        #obtenet similaridad\n",
        "        cos_scores = similaridad(texto_vectorizado_str,ruta_completa)\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "\n",
        "        # Obtener similitud como valor numérico\n",
        "        cos_score_numeric = cos_scores.item()\n",
        "        print(cos_score_numeric)\n",
        "\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "        similarity_scores.append(cos_score_numeric)\n",
        "\n",
        "        # Resultados\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {cos_scores}\")\n",
        "\n",
        "    else:\n",
        "        # Si ruta o figura no son válidos, asignar la frase y continuar con la próxima iteración\n",
        "        similaridad_frase = \"No contiene IMÁGENES\"\n",
        "        similarity_scores.append(similaridad_frase)\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {similaridad_frase}\")\n",
        "        continue\n",
        "\n",
        "# Agregar una nueva columna con las similaridades de cada figura\n",
        "similaridad_scores_cpu = [score.cpu().numpy()[0] if isinstance(score, torch.Tensor) else score for score in similarity_scores]\n",
        "df['similaridad'] = similaridad_scores_cpu\n",
        "\n",
        "# Guardar el nuevo DataFrame con la columna 'tamano' y 'similaridad' como un nuevo archivo CSV\n",
        "ruta_nuevo_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg_con_similaridad_stopwords.csv'\n",
        "df.to_csv(ruta_nuevo_csv, index=False)\n",
        "print(df.head())\n",
        "\n",
        "# Imprimir mensaje de confirmación\n",
        "print(f\"Archivo CSV con las columnas 'tamano' y 'similaridad' guardado en: {ruta_nuevo_csv}\")\n"
      ],
      "metadata": {
        "id": "bJkeQc-UqKAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "\n",
        "# ruta archivo\n",
        "ruta_csv1 = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_Papers_labeled - CSV_Papers_labeled (2).csv'\n",
        "ruta_csv2 = '/content/drive/MyDrive/pruebasNadia/iclr_img/CSV_Papers_labeled2.csv'\n",
        "# leer el archivo csv y convertirlo en DataFrame\n",
        "df1 = pd.read_csv(ruta_csv1)\n",
        "df2 = pd.read_csv(ruta_csv2)\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "print(df.head())\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Función para contar las palabras en un texto\n",
        "def contar_palabras(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "        palabras = texto.split()\n",
        "        return len(palabras)\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor 0\n",
        "        return 0\n",
        "\n",
        "# Función para limpiar texto\n",
        "def limpiar_texto(texto):\n",
        "    # Comprobar si el valor es nulo (NaN)\n",
        "    if isinstance(texto, str):\n",
        "\n",
        "        texto_limpio = re.sub(r'[^\\x00-\\x7F]+', ' ', texto)  # Eliminar caracteres no en inglés\n",
        "        texto_limpio = re.sub(r'[^\\w\\s]', '', texto_limpio)  # Eliminar signos de puntuación\n",
        "        texto_limpio = re.sub(r'\\s+', ' ', texto_limpio).strip()  # Reemplazar espacios dobles por uno solo\n",
        "\n",
        "        # Filtrar stopwords en inglés\n",
        "        words = texto_limpio.split()\n",
        "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "        texto_filtrado = ' '.join(filtered_words)\n",
        "\n",
        "        return texto_filtrado\n",
        "    else:\n",
        "        # Si el valor es nulo devolver valor asignado\n",
        "        return ''\n",
        "\n",
        "\n",
        "def similaridad(texto,ruta):\n",
        "  text_tokens = model.tokenize([texto])\n",
        "  #print(text_tokens)\n",
        "  num_tokens = len(text_tokens['input_ids'][0])\n",
        "  print(num_tokens)\n",
        "\n",
        "  if num_tokens <= 77:\n",
        "    # Encode an image:\n",
        "    print(ruta)\n",
        "    img_emb = model.encode(Image.open(ruta), convert_to_tensor=True)\n",
        "\n",
        "    text_emb = model.encode([texto], convert_to_tensor=True)\n",
        "    # Ensure compatible dimensions for multiplication\n",
        "    text_emb = text_emb.squeeze(0)\n",
        "    # Asegurarte de que text_emb tenga las mismas dimensiones que img_emb\n",
        "    text_emb_expanded = text_emb.expand_as(img_emb)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    cos_scores = util.cos_sim(img_emb, text_emb_expanded)\n",
        "    return cos_scores\n",
        "  else:\n",
        "    # Dividir el texto exactamente a la mitad\n",
        "    longitud_texto = len(texto)\n",
        "    mitad = longitud_texto // 2\n",
        "    fragmento1 = texto[:mitad]\n",
        "    fragmento2 = texto[mitad:]\n",
        "\n",
        "    # Llamar recursivamente la función similaridad para ambos fragmentos\n",
        "    cos_scores1 = similaridad(fragmento1, ruta)\n",
        "    cos_scores2 = similaridad(fragmento2, ruta)\n",
        "\n",
        "    # Calcular el promedio de las similitudes de ambos fragmentos\n",
        "    promedio_similitudes = (cos_scores1 + cos_scores2) / 2\n",
        "    return promedio_similitudes\n",
        "\n",
        "# Agregar nueva columna llamada \"tamano\"\n",
        "df['tamano'] = df['texto_figura'].apply(contar_palabras)\n",
        "\n",
        "# Seleccionar modelo preentrenado\n",
        "model = SentenceTransformer('clip-ViT-B-32')\n",
        "#model = SentenceTransformer('clip-ViT-B-32', device='cuda')\n",
        "\n",
        "# Lista para almacenar las puntuaciones de similitud\n",
        "similarity_scores = []\n",
        "\n",
        "# Iterar sobre cada fila del df\n",
        "for index, row in df.iterrows():\n",
        "    # Obtener los valores de las columnas para la fila actual\n",
        "    archivo = row['archivo']\n",
        "    figura = row['figura']\n",
        "    texto_figura = row['texto_figura']\n",
        "    label = row['label']\n",
        "    ruta = row['ruta']\n",
        "\n",
        "    # Limitar la longitud del texto\n",
        "    texto_figura_limpio = limpiar_texto(texto_figura)\n",
        "    # Encode text description\n",
        "    print(texto_figura_limpio)\n",
        "\n",
        "    # Verificar si ruta y figura son valores válidos\n",
        "    if ruta and isinstance(figura, str):\n",
        "        ruta_completa = os.path.join('/content/drive/MyDrive/pruebasNadia/iclr_img/', str(ruta), figura + \".png\")\n",
        "\n",
        "        vectorizer = CountVectorizer()\n",
        "        texto_vectorizado = vectorizer.fit_transform([texto_figura_limpio])\n",
        "        texto_vectorizado_str = ' '.join(vectorizer.inverse_transform(texto_vectorizado)[0].astype(str))\n",
        "\n",
        "        #obtenet similaridad\n",
        "        cos_scores = similaridad(texto_vectorizado_str,ruta_completa)\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "\n",
        "        # Obtener similitud como valor numérico\n",
        "        cos_score_numeric = cos_scores.item()\n",
        "        print(cos_score_numeric)\n",
        "\n",
        "        # Agregar el resultado de la similitud al DataFrame\n",
        "        similarity_scores.append(cos_score_numeric)\n",
        "\n",
        "        # Resultados\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {cos_scores}\")\n",
        "\n",
        "    else:\n",
        "        # Si ruta o figura no son válidos, asignar la frase y continuar con la próxima iteración\n",
        "        similaridad_frase = \"No contiene IMÁGENES\"\n",
        "        similarity_scores.append(similaridad_frase)\n",
        "        print(f\"Archivo: {archivo}, Figura: {figura}, Label: {label}, Similaridad: {similaridad_frase}\")\n",
        "        continue\n",
        "\n",
        "# Agregar una nueva columna con las similaridades de cada figura\n",
        "similaridad_scores_cpu = [score.cpu().numpy()[0] if isinstance(score, torch.Tensor) else score for score in similarity_scores]\n",
        "df['similaridad'] = similaridad_scores_cpu\n",
        "\n",
        "# Guardar el nuevo DataFrame con la columna 'tamano' y 'similaridad' como un nuevo archivo CSV\n",
        "ruta_nuevo_csv = '/content/drive/MyDrive/pruebasNadia/Extraer IMG/dataimg_iclr_similaridad_stopwords.csv'\n",
        "df.to_csv(ruta_nuevo_csv, index=False)\n",
        "print(df.head())\n",
        "\n",
        "# Imprimir mensaje de confirmación\n",
        "print(f\"Archivo CSV con las columnas 'tamano' y 'similaridad' guardado en: {ruta_nuevo_csv}\")\n"
      ],
      "metadata": {
        "id": "vbwu-U8hAfVB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}